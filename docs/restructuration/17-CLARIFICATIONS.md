# ğŸ”„ RÃ©vision Architecture - Clarifications

## Questions et RÃ©ponses

### Q1 : Event-Log - Pourquoi ne pas sÃ©parer Store et Stream ?

**Ce que "sÃ©parer" voudrait dire :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  event-store    â”‚     â”‚  event-stream   â”‚
â”‚  POST /events   â”‚â”€â”€â”€â”€â–ºâ”‚  GET /stream    â”‚
â”‚  (Ã©crit SQLite) â”‚     â”‚  (lit SQLite)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
           SQLite DB
           (partagÃ©e)
```

**ProblÃ¨mes :**
1. **MÃªme DB** : Les deux services accÃ¨dent au mÃªme fichier SQLite
2. **Conflits** : Ã‰criture et lecture concurrentes = risques
3. **Synchronisation** : Comment stream sait qu'un nouveau event est arrivÃ© ?

**Solution classique pour sÃ©parer :** Message queue (Redis, RabbitMQ)
```
event-store â”€â”€â–º Redis PubSub â”€â”€â–º event-stream
                    â”‚
                    â””â”€â”€â–º SQLite (backup)
```

Mais c'est over-engineering pour notre cas.

**Conclusion : Garder event-log comme 1 service**
- `POST /events` : Ã‰crit en DB + notifie les streams actifs
- `GET /stream` : SSE qui Ã©coute les notifications

---

### Q2 : Prompt-Builder - Que fait-il EXACTEMENT ?

#### ResponsabilitÃ©
> Transformer un `TriggerEvent` + contexte en `messages[]` pour le LLM

#### Input
```python
class PromptRequest(BaseModel):
    source: str              # "telegram", "chat_ui"
    user_id: str
    user_message: str
    conversation_history: list[Message]  # Derniers messages
    user_memories: list[Memory]          # Faits/prÃ©fÃ©rences
    trigger_instructions: str | None     # Instructions custom
```

#### Output
```python
class PromptResponse(BaseModel):
    messages: list[Message]  # PrÃªt pour le LLM
    metadata: dict           # Debug info
```

#### Exemple concret

**Input :**
```json
{
  "source": "telegram",
  "user_id": "123",
  "user_message": "Quel temps fait-il ?",
  "conversation_history": [
    {"role": "user", "content": "Salut"},
    {"role": "assistant", "content": "Bonjour ! Comment puis-je t'aider ?"}
  ],
  "user_memories": [
    {"category": "preference", "content": "Habite Ã  Paris"},
    {"category": "preference", "content": "PrÃ©fÃ¨re les rÃ©ponses courtes"}
  ],
  "trigger_instructions": null
}
```

**Output :**
```json
{
  "messages": [
    {
      "role": "system",
      "content": "Tu es un assistant personnel intelligent.\n\nRÃ¨gles:\n- RÃ©ponds de maniÃ¨re concise\n- Utilise les tools disponibles\n- Termine avec task_complete\n\nContexte utilisateur:\n- Habite Ã  Paris\n- PrÃ©fÃ¨re les rÃ©ponses courtes"
    },
    {
      "role": "user",
      "content": "Salut"
    },
    {
      "role": "assistant", 
      "content": "Bonjour ! Comment puis-je t'aider ?"
    },
    {
      "role": "user",
      "content": "Quel temps fait-il ?"
    }
  ],
  "metadata": {
    "memories_injected": 2,
    "history_messages": 2,
    "template_used": "default"
  }
}
```

#### Ce que prompt-builder NE fait PAS
- âŒ Appeler le LLM
- âŒ ExÃ©cuter des tools
- âŒ Stocker quoi que ce soit
- âŒ GÃ©rer les tokens/auth

#### Pourquoi c'est utile de sÃ©parer ?
| Avantage | Explication |
|----------|-------------|
| **Tests** | Tester les prompts sans LLM (mock) |
| **ItÃ©ration** | Modifier prompts sans toucher la loop |
| **A/B Test** | Comparer versions de prompts |
| **Debug** | Voir exactement ce que le LLM reÃ§oit |
| **SpÃ©cialisation** | Prompts diffÃ©rents par source |

---

### Q3 : Memory - Comment restructurer ?

#### ProblÃ¨me actuel
```
core/
â”œâ”€â”€ memory-store/    # CRUD
â””â”€â”€ memory-search/   # Recherche

interfaces/
â””â”€â”€ memory/
    â””â”€â”€ observer/    # Ã‰coute event-log â†’ Ã©crit dans store
```

Memory est Ã©clatÃ© entre core et interfaces. C'est incohÃ©rent.

#### Analyse : Memory est-il une interface ?

| CritÃ¨re | Interface standard | Memory |
|---------|-------------------|--------|
| ReÃ§oit input externe | âœ… Webhook/API | âŒ ReÃ§oit des events internes |
| Envoie vers externe | âœ… Telegram API | âŒ Ã‰crit en local |
| Pattern trigger/observer/sender | âœ… | âŒ Juste observer |

**Conclusion : Memory n'est PAS une interface, c'est un service core**

#### Solution : Memory = 1 service core

```
core/memory/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py           # FastAPI
â”œâ”€â”€ store.py          # CRUD (write/read)
â”œâ”€â”€ search.py         # Recherche (query)
â”œâ”€â”€ observer.py       # Background task: Ã©coute event-log
â””â”€â”€ database.py       # SQLite
```

**Endpoints :**
- `POST /write` - Ã‰crire une mÃ©moire
- `GET /read/{id}` - Lire une mÃ©moire
- `POST /search` - Rechercher
- `GET /health` - Status (inclut observer status)

**Observer intÃ©grÃ© :**
```python
# main.py
@app.on_event("startup")
async def startup():
    asyncio.create_task(observe_event_log())

async def observe_event_log():
    """Background task qui Ã©coute event-log pour memory_write"""
    async with httpx.AsyncClient() as client:
        async with client.stream("GET", f"{EVENT_LOG_URL}/stream?type=memory_write") as response:
            async for line in response.aiter_lines():
                if line.startswith("data:"):
                    event = json.loads(line[5:])
                    await write_memory(event["data"])
```

#### Avantages
1. **CohÃ©rent** : Memory entiÃ¨rement dans core/
2. **Simple** : 1 service au lieu de 3
3. **Logique** : L'observer est un dÃ©tail d'implÃ©mentation, pas un service

---

## ğŸ—ï¸ Architecture RÃ©visÃ©e

### Core Services (6)

| Service | Port | ResponsabilitÃ© |
|---------|------|----------------|
| `ai-brain` | 8080 | Orchestration boucle agentique |
| `copilot-client` | 8081 | Connexion LLM (token, streaming) |
| `mcp-server` | 8082 | ExÃ©cution tools (plugins) |
| `prompt-builder` | 8083 | Construction des prompts |
| `event-log` | 8085 | Stockage + streaming events |
| `memory` | 8086 | CRUD + Search + Observer interne |

### Interfaces (3 par canal)

```
interfaces/
â”œâ”€â”€ telegram/     (trigger + observer + sender)
â”œâ”€â”€ chat-ui/      (trigger + observer + sender)
â””â”€â”€ email/        (trigger + observer + sender)
```

**Note : Plus de `interfaces/memory/`** - Memory est dans core.

### Formule containers
```
Total = 6 (core) + 3 Ã— N (interfaces)

Avec Telegram + Chat-UI :
= 6 + 6 = 12 containers
```

---

## ğŸ“Š Comparaison

| Aspect | Avant (V2.2) | AprÃ¨s (V2.3) |
|--------|--------------|--------------|
| Core services | 7 | 6 |
| Memory services | 3 (store + search + observer) | 1 |
| Memory dans interfaces | âœ… Oui (observer) | âŒ Non |
| CohÃ©rence | âš ï¸ Memory Ã©clatÃ© | âœ… Memory unifiÃ© |
| ComplexitÃ© | Plus Ã©levÃ©e | RÃ©duite |

---

## ğŸ”„ Nouveau Diagramme

```mermaid
flowchart TB
    subgraph Interfaces["ğŸ“± INTERFACES"]
        subgraph TG["telegram/"]
            TG_T["trigger"]
            TG_O["observer"]
            TG_S["sender"]
        end
        subgraph CU["chat-ui/"]
            CU_T["trigger"]
            CU_O["observer"]
            CU_S["sender"]
        end
    end

    subgraph Core["ğŸ§  CORE"]
        AI["ai-brain"]
        PB["prompt-builder"]
        COP["copilot-client"]
        MCP["mcp-server"]
        LOG["event-log"]
        MEM["memory<br/>(store+search+observer)"]
    end

    TG_T & CU_T -->|TriggerEvent| AI
    AI -->|build| PB
    AI <-->|stream| COP
    AI -->|execute| MCP
    MCP -->|search| MEM
    AI -->|emit| LOG
    
    LOG -.->|SSE| TG_O
    LOG -.->|SSE| CU_O
    LOG -.->|SSE memory_write| MEM
    
    TG_O --> TG_S
    CU_O --> CU_S

    style AI fill:#fff3e0,stroke:#e65100
    style PB fill:#fce4ec,stroke:#c2185b
    style COP fill:#e1f5fe,stroke:#0288d1
    style MCP fill:#f3e5f5,stroke:#7b1fa2
    style LOG fill:#e3f2fd,stroke:#1565c0
    style MEM fill:#e8f5e9,stroke:#2e7d32
```
