# ðŸ”¬ Analyse des SÃ©parations de Services

> RÃ©flexion sur les services qui pourraient Ãªtre encore sÃ©parÃ©s.

---

## 1ï¸âƒ£ Memory : Une Interface comme les autres ?

### Observation
Tu as raison : `memory` ressemble Ã  une interface !
- Elle **observe** event-log (comme telegram-observer)
- Elle **stocke** des donnÃ©es (comme un sender stocke vers l'extÃ©rieur)
- Elle **rÃ©pond** Ã  des requÃªtes (search)

### Comparaison

| Composant | Telegram | Memory |
|-----------|----------|--------|
| Trigger | ReÃ§oit message Telegram | âŒ N/A (pas de trigger externe) |
| Observer | Ã‰coute `send_telegram` | Ã‰coute `memory_write` |
| Sender/Store | Envoie via API Telegram | Stocke dans SQLite |
| + Extra | - | Expose `/search` (lecture) |

### Proposition : 3 services pour Memory

```
core/memory/
â”œâ”€â”€ store/           # Stockage CRUD
â”‚   â”œâ”€â”€ main.py      # POST /write, GET /read
â”‚   â””â”€â”€ database.py  # SQLite
â”‚
â”œâ”€â”€ search/          # Recherche sÃ©mantique
â”‚   â”œâ”€â”€ main.py      # POST /search
â”‚   â””â”€â”€ embeddings.py # (futur: vectoriel)
â”‚
â””â”€â”€ observer/        # Ã‰coute event-log
    â”œâ”€â”€ main.py      # SSE â†’ filtre memory_write â†’ store
    â””â”€â”€ ...
```

### Flow

```
ai-brain â”€â”€emit memory_writeâ”€â”€â–º event-log
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
            memory-observer â”€â”€â–º memory-store (write)
                    
mcp-server â”€â”€memory_read toolâ”€â”€â–º memory-search â”€â”€â–º memory-store (read)
```

### BÃ©nÃ©fices
| Avant | AprÃ¨s |
|-------|-------|
| 1 service qui fait 3 choses | 3 services avec 1 responsabilitÃ© |
| Difficile de changer le stockage | Remplacer `store` par Postgres = 1 service |
| Difficile d'ajouter vectoriel | Ajouter dans `search` sans toucher le reste |

---

## 2ï¸âƒ£ Event-Log : Store + Stream

### Ce que fait event-log actuellement

1. **Recevoir** les LogEvents (POST /events)
2. **Stocker** dans SQLite (append-only)
3. **Streamer** via SSE (GET /stream)

### Faut-il sÃ©parer ?

| Option | Pour | Contre |
|--------|------|--------|
| **Garder ensemble** | Simple, mÃªme DB | Couplage store/stream |
| **SÃ©parer** | Isolation pure | Over-engineering ? |

### Analyse

```
POST /events  â”€â”€â–º  SQLite  â”€â”€â–º  GET /stream
     â”‚                              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€ MÃŠME DB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Le store et le stream utilisent la **mÃªme base de donnÃ©es**. Les sÃ©parer impliquerait :
- Soit partager le volume SQLite (pas propre)
- Soit avoir 2 DBs synchronisÃ©es (complexe)
- Soit stream en mÃ©moire seulement (perd la persistence)

### Verdict : âŒ Ne pas sÃ©parer

Event-log est un cas oÃ¹ le stockage ET le streaming sont intrinsÃ¨quement liÃ©s. C'est comme une base de donnÃ©es avec son API - on ne sÃ©pare pas PostgreSQL de son protocole rÃ©seau.

**Exception** : Si on migrait vers un vrai event store (Kafka, EventStoreDB), alors la sÃ©paration serait naturelle.

---

## 3ï¸âƒ£ Prompt-Builder : Service dÃ©diÃ© ?

### Ce que ferait prompt-builder

```python
# EntrÃ©e
{
  "user_message": "CrÃ©e un site web",
  "conversation_history": [...],
  "user_memories": [...],
  "available_tools": [...],
  "source": "telegram"
}

# Sortie
{
  "messages": [
    {"role": "system", "content": "Tu es un assistant..."},
    {"role": "user", "content": "...contexte..."},
    {"role": "user", "content": "CrÃ©e un site web"}
  ]
}
```

### ResponsabilitÃ©s

| TÃ¢che | Description |
|-------|-------------|
| System prompt | GÃ©nÃ©rer le prompt systÃ¨me selon le contexte |
| Injection mÃ©moire | Ajouter les memories pertinentes |
| Formatage conversation | Structurer l'historique |
| Adaptation interface | Prompts diffÃ©rents selon telegram/chat-ui |
| Instructions source | Ajouter les instructions du trigger |

### BÃ©nÃ©fices

1. **Testable isolÃ©ment** : Tester les prompts sans l'IA
2. **ItÃ©rable** : Changer les prompts sans toucher ai-brain
3. **A/B testing** : Tester diffÃ©rentes versions de prompts
4. **SpÃ©cialisable** : Prompts diffÃ©rents par interface

### Structure proposÃ©e

```
core/prompt-builder/
â”œâ”€â”€ main.py           # FastAPI POST /build
â”œâ”€â”€ templates/        # Templates de prompts
â”‚   â”œâ”€â”€ system.py     # Prompt systÃ¨me de base
â”‚   â”œâ”€â”€ telegram.py   # Adaptations Telegram
â”‚   â”œâ”€â”€ chat_ui.py    # Adaptations Chat-UI
â”‚   â””â”€â”€ email.py      # Adaptations Email
â”œâ”€â”€ injectors/        # Plugins d'injection
â”‚   â”œâ”€â”€ memory.py     # Injecte les memories
â”‚   â”œâ”€â”€ history.py    # Injecte l'historique
â”‚   â””â”€â”€ tools.py      # Injecte la liste des tools
â””â”€â”€ requirements.txt
```

### Contrat

```python
@app.post("/build")
async def build_prompt(request: PromptRequest) -> PromptResponse:
    """
    Construit le prompt complet pour l'IA
    
    Input:
    - user_message: str
    - source: str (telegram, chat_ui, email)
    - session_id: str
    - user_id: str
    
    Output:
    - messages: list[Message]
    - metadata: dict (debug info)
    """
```

### Verdict : âœ… Bonne idÃ©e

SÃ©parer le prompt-builder permet de :
- ItÃ©rer sur les prompts sans risquer la boucle
- Tester les prompts en isolation
- Avoir des prompts spÃ©cialisÃ©s par interface

---

## 4ï¸âƒ£ Gateway devant AI-Brain ?

### Ce que ferait un gateway

```
Trigger â”€â”€â–º Gateway â”€â”€â–º AI-Brain
               â”‚
               â”œâ”€â”€ Auth / Rate limit
               â”œâ”€â”€ Validation du TriggerEvent
               â”œâ”€â”€ Load balancing (si multiple ai-brain)
               â””â”€â”€ Logging / Metrics
```

### Faut-il le faire ?

| Pour | Contre |
|------|--------|
| Auth centralisÃ©e | PrÃ©maturÃ© (pas d'auth V1) |
| Rate limiting | Peut Ãªtre dans ai-brain |
| Metrics | Peut Ãªtre dans ai-brain |
| Load balancing | 1 seul ai-brain pour l'instant |

### Verdict : âŒ Pas maintenant

Un gateway serait utile si :
- Multiple instances de ai-brain
- Auth complexe
- Rate limiting sophistiquÃ©

Pour la V1, c'est de l'over-engineering. Les triggers envoient directement Ã  ai-brain.

**Ã€ reconsidÃ©rer** quand on aura besoin de scaling horizontal.

---

## ðŸ“Š RÃ©sumÃ© des dÃ©cisions

| Service | SÃ©parer ? | Justification |
|---------|-----------|---------------|
| **memory** | âœ… OUI (3 services) | store + search + observer = 3 responsabilitÃ©s |
| **event-log** | âŒ NON | Store et stream partagent la mÃªme DB |
| **prompt-builder** | âœ… OUI | Testable, itÃ©rable, spÃ©cialisable |
| **gateway** | âŒ NON (V1) | PrÃ©maturÃ©, pas de besoin actuel |

---

## ðŸ—ï¸ Architecture Finale Mise Ã  Jour

### Core Services (7)

| Service | Port | ResponsabilitÃ© |
|---------|------|----------------|
| `ai-brain` | 8080 | Orchestration boucle |
| `copilot-client` | 8081 | Connexion LLM |
| `mcp-server` | 8082 | ExÃ©cution tools |
| `prompt-builder` | 8083 | Construction prompts |
| `event-log` | 8085 | Stockage + streaming events |
| `memory-store` | 8086 | CRUD mÃ©moire |
| `memory-search` | 8087 | Recherche mÃ©moire |

### Memory Observer = Interface

```
interfaces/memory/
â””â”€â”€ observer/
    â”œâ”€â”€ main.py          # Ã‰coute memory_write â†’ appelle memory-store
    â””â”€â”€ requirements.txt
```

Pas de trigger (pas d'input externe) ni de sender (pas d'output externe).

### Formule mise Ã  jour

```
Total = 7 (core) + 1 (memory-observer) + 3 Ã— N (interfaces)

Avec Telegram + Chat-UI :
= 7 + 1 + (3 Ã— 2) = 14 containers
```

---

## ðŸ”„ Nouveau Flow

```mermaid
flowchart TB
    subgraph Triggers
        TG_T[telegram-trigger]
        CU_T[chatui-trigger]
    end
    
    subgraph Core
        PB[prompt-builder]
        AI[ai-brain]
        COP[copilot-client]
        MCP[mcp-server]
        LOG[event-log]
    end
    
    subgraph Memory
        MS[memory-store]
        MSR[memory-search]
        MO[memory-observer]
    end
    
    subgraph Observers
        TG_O[telegram-observer]
        CU_O[chatui-observer]
    end
    
    TG_T & CU_T -->|TriggerEvent| AI
    AI -->|build| PB
    AI <-->|stream| COP
    AI -->|execute| MCP
    MCP -->|search| MSR
    MSR --> MS
    AI -->|emit| LOG
    LOG -.->|SSE| MO
    LOG -.->|SSE| TG_O
    LOG -.->|SSE| CU_O
    MO -->|write| MS
```
